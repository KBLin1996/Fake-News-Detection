{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Traditional Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "df = pd.read_csv(\"../data/processed/final_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to vectorize features\n",
    "def prep_features(df, use_clean, use_date): \n",
    "    if use_clean:\n",
    "        text = df[\"clean_content\"]\n",
    "    else:\n",
    "        text = df[\"content\"]\n",
    "\n",
    "    # Vectorizing text input\n",
    "    vectorizer = TfidfVectorizer(min_df= 3, stop_words=\"english\", sublinear_tf = True, norm = 'l2', ngram_range = (1, 2))\n",
    "    text_processed = vectorizer.fit_transform(text).toarray()\n",
    "\n",
    "    with open(\"vectorizer\", \"wb\") as f:\n",
    "        pickle.dump(vectorizer, f)\n",
    "\n",
    "    if use_date:\n",
    "        # One-Hot Encoding to process Dates\n",
    "        date_processed = LabelBinarizer().fit_transform(df.date)\n",
    "        features = np.concatenate((date_processed, text_processed), axis = 1)\n",
    "    else:\n",
    "        features = text_processed\n",
    "    \n",
    "    print(type(features))\n",
    "\n",
    "    return features\n",
    "\n",
    "# Finalize training and testing data\n",
    "def prep_data(df, use_clean, use_date):\n",
    "    X = prep_features(df, use_clean, use_date)\n",
    "    Y = df[\"reliability\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "    print(type(X_train))\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to train and test model.\n",
    "# Returns dataframe of misclassified data\n",
    "\n",
    "def train_test_model(model_name, df, save, use_clean, use_date):\n",
    "    X_train, X_test, y_train, y_test = prep_data(df, use_clean, use_date)\n",
    "\n",
    "    if (model_name == \"LR\"):\n",
    "        model = generate_model_LR(X_train, y_train)\n",
    "    \n",
    "    if (model_name == \"SVM\"):\n",
    "        model = generate_model_SVM(X_train, y_train)\n",
    "\n",
    "    if (model_name == \"NB\"):\n",
    "        model = generate_model_NB(X_train, y_train)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    if (save):\n",
    "        with open(\"model_instances/\" + model_name, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    ytest = np.array(y_test)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # confusion matrix and classification report(precision, recall, F1-score)\n",
    "    print(\"Model Accuracy: \" + str(accuracy_score(ytest, predictions)))  \n",
    "    print(\"Precision Score: \" + str(precision_score(ytest, predictions)))\n",
    "    print(\"Recall Score: \" + str(recall_score(ytest, predictions)))\n",
    "    print(\"F1 Score: \" + str(f1_score(ytest, predictions)))\n",
    "\n",
    "    print(\"Confusion Matrix: \")\n",
    "    print(confusion_matrix(ytest, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Hyperparameter Tuning  & Model Instance Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_LR(X_train, y_train):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    grid = {\n",
    "        \"penalty\": [\"none\", \"l1\", \"l2\", \"elasticnet\"],\n",
    "        \"C\":  [1e-3, 10],\n",
    "        \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "    }\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    search = GridSearchCV(LogisticRegression(), grid, scoring = \"accuracy\", n_jobs = -1, cv = cv)\n",
    "    result = search.fit(X_train, y_train)\n",
    "\n",
    "    return result.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Train and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9188701923076923\n",
      "Precision Score: 0.9233926128590971\n",
      "Recall Score: 0.8952254641909815\n",
      "F1 Score: 0.9090909090909092\n",
      "Confusion Matrix: \n",
      "[[854  56]\n",
      " [ 79 675]]\n"
     ]
    }
   ],
   "source": [
    "train_test_model(\"LR\", df, save=False, use_clean=True, use_date=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9272836538461539\n",
      "Precision Score: 0.9389736477115118\n",
      "Recall Score: 0.8978779840848806\n",
      "F1 Score: 0.9179661016949152\n",
      "Confusion Matrix: \n",
      "[[866  44]\n",
      " [ 77 677]]\n"
     ]
    }
   ],
   "source": [
    "train_test_model(\"LR\", df, save=False, use_clean=True, use_date=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9134615384615384\n",
      "Precision Score: 0.9284712482468443\n",
      "Recall Score: 0.8768211920529801\n",
      "F1 Score: 0.901907356948229\n",
      "Confusion Matrix: \n",
      "[[858  51]\n",
      " [ 93 662]]\n"
     ]
    }
   ],
   "source": [
    "train_test_model(\"LR\", df, save=False, use_clean=False, use_date=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9140625\n",
      "Precision Score: 0.9117259552042161\n",
      "Recall Score: 0.9010416666666666\n",
      "F1 Score: 0.9063523248199084\n",
      "Confusion Matrix: \n",
      "[[829  67]\n",
      " [ 76 692]]\n"
     ]
    }
   ],
   "source": [
    "train_test_model(\"LR\", df, save=False, use_clean=False, use_date=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Hyperparameter Tuning  & Model Instance Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_SVM(X_train, y_train):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    grid = {\n",
    "        'C': [1, 0.01],\n",
    "        'gamma': [1, 0.1, \"scale\"],\n",
    "        'kernel': ['rbf', \"linear\"]\n",
    "    }\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    search = GridSearchCV(SVC(), grid, scoring = \"accuracy\", n_jobs = -1, cv = cv)\n",
    "    result = search.fit(X_train, y_train)\n",
    "\n",
    "    return result.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Train and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 1, 'kernel': 'linear'}\n",
      "Model Accuracy: 0.9350961538461539\n",
      "Precision Score: 0.9586114819759679\n",
      "Recall Score: 0.9031446540880503\n",
      "F1 Score: 0.9300518134715026\n",
      "Confusion Matrix: \n",
      "[[838  31]\n",
      " [ 77 718]]\n"
     ]
    }
   ],
   "source": [
    "train_test_model(\"SVM\", df, save=False, use_clean=True, use_date=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Model Accuracy: 0.9320913461538461\n",
      "Precision Score: 0.9296551724137931\n",
      "Recall Score: 0.9157608695652174\n",
      "F1 Score: 0.9226557152635181\n",
      "Confusion Matrix: \n",
      "[[877  51]\n",
      " [ 62 674]]\n"
     ]
    }
   ],
   "source": [
    "train_test_model(\"SVM\", df, save=False, use_clean=True, use_date=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(\"SVM\", df, save=False, use_clean=False, use_date=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9278846153846154\n",
      "Precision Score: 0.9412550066755674\n",
      "Recall Score: 0.9026888604353394\n",
      "F1 Score: 0.9215686274509803\n",
      "Confusion Matrix: \n",
      "[[839  44]\n",
      " [ 76 705]]\n"
     ]
    }
   ],
   "source": [
    "train_test_model(\"SVM\", df, save=False, use_clean=False, use_date=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Hyperparameter Tuning and Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_NB(X_train, y_train):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    grid = {\n",
    "        'var_smoothing': [1e-13, 1e-12, 1e-11, 1e-10, 1e-9]\n",
    "    }\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    search = GridSearchCV(GaussianNB(), grid, scoring = \"accuracy\", n_jobs = -1, cv = cv)\n",
    "    result = search.fit(X_train, y_train)\n",
    "    \n",
    "    return result.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Train and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 1e-13}\n",
      "Model Accuracy: 0.8816105769230769\n",
      "Precision Score: 0.8502994011976048\n",
      "Recall Score: 0.907928388746803\n",
      "F1 Score: 0.878169449598021\n",
      "Confusion Matrix: \n",
      "[[757 125]\n",
      " [ 72 710]]\n"
     ]
    }
   ],
   "source": [
    "train_test_model(\"NB\", df, save=False, use_clean=True, use_date=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 1e-09}\n",
      "Model Accuracy: 0.8731971153846154\n",
      "Precision Score: 0.8419117647058824\n",
      "Recall Score: 0.893368010403121\n",
      "F1 Score: 0.8668769716088328\n",
      "Confusion Matrix: \n",
      "[[766 129]\n",
      " [ 82 687]]\n"
     ]
    }
   ],
   "source": [
    "train_test_model(\"NB\", df, save=False, use_clean=True, use_date=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 1e-13}\n",
      "Model Accuracy: 0.8876201923076923\n",
      "Precision Score: 0.8768656716417911\n",
      "Recall Score: 0.8890290037831021\n",
      "F1 Score: 0.8829054477144647\n",
      "Confusion Matrix: \n",
      "[[772  99]\n",
      " [ 88 705]]\n"
     ]
    }
   ],
   "source": [
    "train_test_model(\"NB\", df, save=False, use_clean=False, use_date=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 1e-13}\n",
      "Model Accuracy: 0.8816105769230769\n",
      "Precision Score: 0.8697368421052631\n",
      "Recall Score: 0.8708827404479579\n",
      "F1 Score: 0.8703094140882159\n",
      "Confusion Matrix: \n",
      "[[806  99]\n",
      " [ 98 661]]\n"
     ]
    }
   ],
   "source": [
    "train_test_model(\"NB\", df, save=False, use_clean=False, use_date=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Misclassified Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_misclassified(model_name, df, save):\n",
    "    X = prep_features(df, False, False)\n",
    "    Y = df[\"reliability\"]\n",
    "\n",
    "    with open(\"model_instances/\" + model_name, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    predictions = model.predict(X)\n",
    "    misclassified = np.where(Y != predictions)\n",
    "    misclassified_df = df.iloc[misclassified]\n",
    "\n",
    "    if (save):\n",
    "        misclassified_df.to_csv(\"misclassified_data/\" + model_name + \".csv\", index=False)\n",
    "\n",
    "    return misclassified_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>reliability</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>Social Security recipients to automatically ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>social secur recipi automat get coronaviru money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>Children in need census 2019 to 2020: guide</td>\n",
       "      <td>1</td>\n",
       "      <td>children need censu guid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>Harry Pottering around at home? Rowling to res...</td>\n",
       "      <td>1</td>\n",
       "      <td>harri potter around home rowl rescu bore kid l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>Coronavirus: Over 4,000 cases reported in Penn...</td>\n",
       "      <td>1</td>\n",
       "      <td>coronaviru over 4 case report pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>M&amp;A in Times of COVID-19</td>\n",
       "      <td>1</td>\n",
       "      <td>ma time covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6366</th>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>\"The new Dane County lockdown policy... (has)...</td>\n",
       "      <td>0</td>\n",
       "      <td>the new dane counti lockdown polici effect kil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6405</th>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>A blog article which says that the Italian do...</td>\n",
       "      <td>0</td>\n",
       "      <td>a blog articl say italian doctor expert charg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6436</th>\n",
       "      <td>2020-05-24</td>\n",
       "      <td>Coronavirus multiplies in sewage and pouring ...</td>\n",
       "      <td>0</td>\n",
       "      <td>coronaviru multipli sewag pour bleach sewag wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6531</th>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>Claim that despite the fact that the crisis h...</td>\n",
       "      <td>0</td>\n",
       "      <td>claim despit fact crisi headquart north macedo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>\"George Floyd's 'murder' filmed before COVID-...</td>\n",
       "      <td>0</td>\n",
       "      <td>georg floyd murder film covid â</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                            content  \\\n",
       "73    2020-04-02  Social Security recipients to automatically ge...   \n",
       "88    2020-04-01        Children in need census 2019 to 2020: guide   \n",
       "90    2020-04-01  Harry Pottering around at home? Rowling to res...   \n",
       "147   2020-03-30  Coronavirus: Over 4,000 cases reported in Penn...   \n",
       "169   2020-03-29                           M&A in Times of COVID-19   \n",
       "...          ...                                                ...   \n",
       "6366  2020-05-19   \"The new Dane County lockdown policy... (has)...   \n",
       "6405  2020-05-21   A blog article which says that the Italian do...   \n",
       "6436  2020-05-24   Coronavirus multiplies in sewage and pouring ...   \n",
       "6531  2020-06-03   Claim that despite the fact that the crisis h...   \n",
       "6609  2020-06-14   \"George Floyd's 'murder' filmed before COVID-...   \n",
       "\n",
       "      reliability                                      clean_content  \n",
       "73              1   social secur recipi automat get coronaviru money  \n",
       "88              1                           children need censu guid  \n",
       "90              1  harri potter around home rowl rescu bore kid l...  \n",
       "147             1         coronaviru over 4 case report pennsylvania  \n",
       "169             1                                      ma time covid  \n",
       "...           ...                                                ...  \n",
       "6366            0  the new dane counti lockdown polici effect kil...  \n",
       "6405            0  a blog articl say italian doctor expert charg ...  \n",
       "6436            0  coronaviru multipli sewag pour bleach sewag wa...  \n",
       "6531            0  claim despit fact crisi headquart north macedo...  \n",
       "6609            0                    georg floyd murder film covid â  \n",
       "\n",
       "[162 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_misclassified(\"LR\", df, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>reliability</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>Trump advises voluntary mask use against coron...</td>\n",
       "      <td>1</td>\n",
       "      <td>trump advis voluntari mask use coronaviru wear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>Stamp Duty and Stamp Duty Reserve Tax: transfe...</td>\n",
       "      <td>1</td>\n",
       "      <td>stamp duti stamp duti reserv tax transfer sche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>Social Security recipients to automatically ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>social secur recipi automat get coronaviru money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>Regulatory status of equipment being used to h...</td>\n",
       "      <td>1</td>\n",
       "      <td>regulatori statu equip use help prevent corona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>Indian doctors fight coronavirus with raincoat...</td>\n",
       "      <td>1</td>\n",
       "      <td>indian doctor fight coronaviru raincoat helmet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6111</th>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>\"The mainstream media pretended there was a d...</td>\n",
       "      <td>0</td>\n",
       "      <td>the mainstream medium pretend deadli surg covi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6126</th>\n",
       "      <td>2020-05-09</td>\n",
       "      <td>Under an 1866 Supreme Court ruling, stay-at-h...</td>\n",
       "      <td>0</td>\n",
       "      <td>under suprem court rule stay home order illeg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338</th>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>Texas and Florida have a \"balanced budget\"Â ...</td>\n",
       "      <td>0</td>\n",
       "      <td>texa florida balanc budget â california debt b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6364</th>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>The survival rate for COVID-19 is 98.54% in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>the surviv rate covid uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6619</th>\n",
       "      <td>2020-06-15</td>\n",
       "      <td>\"If we stopped testing right now, we'd have v...</td>\n",
       "      <td>0</td>\n",
       "      <td>if stop test right would case â</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                            content  \\\n",
       "23    2020-04-03  Trump advises voluntary mask use against coron...   \n",
       "50    2020-04-03  Stamp Duty and Stamp Duty Reserve Tax: transfe...   \n",
       "73    2020-04-02  Social Security recipients to automatically ge...   \n",
       "110   2020-04-01  Regulatory status of equipment being used to h...   \n",
       "135   2020-03-31  Indian doctors fight coronavirus with raincoat...   \n",
       "...          ...                                                ...   \n",
       "6111  2020-05-08   \"The mainstream media pretended there was a d...   \n",
       "6126  2020-05-09   Under an 1866 Supreme Court ruling, stay-at-h...   \n",
       "6338  2020-05-18   Texas and Florida have a \"balanced budget\"Â ...   \n",
       "6364  2020-05-19   The survival rate for COVID-19 is 98.54% in t...   \n",
       "6619  2020-06-15   \"If we stopped testing right now, we'd have v...   \n",
       "\n",
       "      reliability                                      clean_content  \n",
       "23              1  trump advis voluntari mask use coronaviru wear...  \n",
       "50              1  stamp duti stamp duti reserv tax transfer sche...  \n",
       "73              1   social secur recipi automat get coronaviru money  \n",
       "110             1  regulatori statu equip use help prevent corona...  \n",
       "135             1  indian doctor fight coronaviru raincoat helmet...  \n",
       "...           ...                                                ...  \n",
       "6111            0  the mainstream medium pretend deadli surg covi...  \n",
       "6126            0  under suprem court rule stay home order illeg ...  \n",
       "6338            0  texa florida balanc budget â california debt b...  \n",
       "6364            0                           the surviv rate covid uk  \n",
       "6619            0                    if stop test right would case â  \n",
       "\n",
       "[133 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_misclassified(\"SVM\", df, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>reliability</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>Europe's north-south lockdown divide revealed ...</td>\n",
       "      <td>1</td>\n",
       "      <td>europ north south lockdown divid reveal googl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>Stamp Duty and Stamp Duty Reserve Tax: transfe...</td>\n",
       "      <td>1</td>\n",
       "      <td>stamp duti stamp duti reserv tax transfer sche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>Mecca, Medina get 24-hour curfew; Gulf migrant...</td>\n",
       "      <td>1</td>\n",
       "      <td>mecca medina get hour curfew gulf migrant work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>China clamps down on coronavirus test kit expo...</td>\n",
       "      <td>1</td>\n",
       "      <td>china clamp coronaviru test kit export accurac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>River Thames: lock and weir fishing permit app...</td>\n",
       "      <td>1</td>\n",
       "      <td>river thame lock weir fish permit applic form</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>\"George Floyd's 'murder' filmed before COVID-...</td>\n",
       "      <td>0</td>\n",
       "      <td>georg floyd murder film covid â</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6617</th>\n",
       "      <td>2020-06-15</td>\n",
       "      <td>The vaccine is not the final solution against...</td>\n",
       "      <td>0</td>\n",
       "      <td>the vaccin final solut novel coronaviru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>2020-06-15</td>\n",
       "      <td>News stories referencing the number \"322\"Â a...</td>\n",
       "      <td>0</td>\n",
       "      <td>new stori referenc number â covid proof case t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6622</th>\n",
       "      <td>2020-06-16</td>\n",
       "      <td>Facebook is using your pictures and posts in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>facebook use pictur post lawsuit compani amid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6635</th>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>This video of the Eiffel Tower shows a tribut...</td>\n",
       "      <td>0</td>\n",
       "      <td>thi video eiffel tower show tribut victim covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>413 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                            content  \\\n",
       "40    2020-04-03  Europe's north-south lockdown divide revealed ...   \n",
       "50    2020-04-03  Stamp Duty and Stamp Duty Reserve Tax: transfe...   \n",
       "62    2020-04-02  Mecca, Medina get 24-hour curfew; Gulf migrant...   \n",
       "101   2020-04-01  China clamps down on coronavirus test kit expo...   \n",
       "124   2020-03-31  River Thames: lock and weir fishing permit app...   \n",
       "...          ...                                                ...   \n",
       "6609  2020-06-14   \"George Floyd's 'murder' filmed before COVID-...   \n",
       "6617  2020-06-15   The vaccine is not the final solution against...   \n",
       "6618  2020-06-15   News stories referencing the number \"322\"Â a...   \n",
       "6622  2020-06-16   Facebook is using your pictures and posts in ...   \n",
       "6635  2020-06-17   This video of the Eiffel Tower shows a tribut...   \n",
       "\n",
       "      reliability                                      clean_content  \n",
       "40              1  europ north south lockdown divid reveal googl ...  \n",
       "50              1  stamp duti stamp duti reserv tax transfer sche...  \n",
       "62              1  mecca medina get hour curfew gulf migrant work...  \n",
       "101             1  china clamp coronaviru test kit export accurac...  \n",
       "124             1      river thame lock weir fish permit applic form  \n",
       "...           ...                                                ...  \n",
       "6609            0                    georg floyd murder film covid â  \n",
       "6617            0            the vaccin final solut novel coronaviru  \n",
       "6618            0  new stori referenc number â covid proof case t...  \n",
       "6622            0  facebook use pictur post lawsuit compani amid ...  \n",
       "6635            0    thi video eiffel tower show tribut victim covid  \n",
       "\n",
       "[413 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_misclassified(\"NB\", df, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Misclassified by both LR and SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_mis = pd.read_csv(\"misclassified_data/LR.csv\")\n",
    "SVM_mis = pd.read_csv(\"misclassified_data/SVM.csv\")\n",
    "\n",
    "temp = pd.concat([LR_mis, SVM_mis])\n",
    "\n",
    "both_LR_SVM_mis = temp[temp.duplicated()]\n",
    "\n",
    "both_LR_SVM_mis.to_csv(\"misclassified_data/both_LR_SVM.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b86f0d2fa08c5cfaee533564080a44b187fd2237f8d59dec528965f0795e352"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
