{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we will generate a fully labeled dataset, with the data coming from two different sources:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data labeled **TRUE**: A selection of articles from the **Aylien** Dataset, retrieved from https://aylien.com/blog/free-coronavirus-news-dataset, including the following\n",
    "    - news articles that come from sources whose credibility rating, according to *Media Bias/Fact Check* (https://mediabiasfactcheck.com/), is the highest possible.\n",
    "    - news articles that come from government sources (e.g., whose source url ends with \".gov\")\n",
    "    - news articles published by world-renowned universities or organizations (e.g., Harvard, WHO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data labeled **FALSE**: Provided directly by COVID-19 Fake News Infodemic Research Dataset (**CoVID19-FNIR Dataset**). The raw **FNIR** dataset was retrieved from https://ieee-dataport.org/open-access/covid-19-fake-news-infodemic-research-dataset-covid19-fnir-dataset, and some preliminary manual procedures have been performed on it before usage. The said procedures include:\n",
    "    1. filling in blank or incomplete entries according to the source URL;\n",
    "    2. fully romanizing foreign names that had indisplayable special characters;\n",
    "    3. converting date string format to the ISO format;\n",
    "    4. removing indescriptive or vague news entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To maintain the same features across the two raw datasets, we have decided to keep the following features only:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- News Content\n",
    "- Date of Publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import date, datetime\n",
    "\n",
    "# Custom imports\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from config import config\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the **Aylien** Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will preprocess the Aylien Dataset. More specifically, for our purposes, we will read the original **Aylien** dataset and take a subset of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with JSONL dataset file\n",
    "# BEGIN: CREDIT GOES TO https://galea.medium.com/how-to-love-jsonl-using-json-line-format-in-your-workflow-b6884f65175b\n",
    "\n",
    "sample_size = 50000\n",
    "aylien_list = []\n",
    "random.seed(config[\"seed\"])\n",
    "\n",
    "with open(\"../data/aylien_covid_news_data.jsonl\", 'r', encoding='utf-8') as f:   \n",
    "    total_num_lines = sum(1 for line in f)\n",
    "    indices = random.sample(range(total_num_lines), sample_size)\n",
    "    \n",
    "    f.seek(0)\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        if i in indices:\n",
    "            aylien_list.append(json.loads(line.rstrip('\\n|\\r')))\n",
    "\n",
    "# END: CREDIT GOES TO https://galea.medium.com/how-to-love-jsonl-using-json-line-format-in-your-workflow-b6884f65175b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/raw/aylien_preprocessed\", \"wb\") as aylien_preprocessed_file:\n",
    "    pickle.dump(aylien_list, aylien_preprocessed_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will load the `pickle` object created in `aylien_preprocessing.ipynb`, which contains the preprocessed  Aylien dataset we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file\n",
    "with open(\"../data/raw/aylien_preprocessed\", \"rb\") as aylien_preprocessed_file:\n",
    "    aylien = pd.DataFrame(pickle.load(aylien_preprocessed_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melon\\AppData\\Local\\Temp\\ipykernel_25360\\1133741381.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  aylien = aylien.drop(['author', 'body','categories', 'characters_count', 'entities', 'hashtags', 'id', 'keywords', 'language',\n"
     ]
    }
   ],
   "source": [
    "# Drop entries that have null values\n",
    "aylien = aylien.dropna()\n",
    "\n",
    "# Drop unnecessary columns first\n",
    "aylien = aylien.drop(['author', 'body','categories', 'characters_count', 'entities', 'hashtags', 'id', 'keywords', 'language', \n",
    "                'links', 'media','paragraphs_count','sentences_count', 'sentiment', 'social_shares_count', 'summary', 'words_count'], 1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns for Consistency\n",
    "aylien = aylien.rename(columns = {\"published_at\": \"date\", \"title\": \"content\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process DATE\n",
    "aylien[\"date\"] = aylien[\"date\"].apply(get_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process SOURCE\n",
    "aylien[\"source\"] = aylien[\"source\"].apply(get_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous operations might have added some more NA values\n",
    "aylien = aylien.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we would like to partially label our **Aylien** dataset. We will do this by the standards described at the beginning of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\melon\\OneDrive\\Rice\\Coursework\\Spring 2022\\DSCI 535 Project\\Project_New\\data_wrangling\\utils.py:108: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  aylien = aylien.drop(\"source\", 1)\n"
     ]
    }
   ],
   "source": [
    "# Label the Aylien dataset\n",
    "aylien = label(aylien)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we would like to split the **Aylien** dataset into labeled and unlabeled parts. The labeled part will later be combined with the **FNIR** dataset, while the unlabeled part will be saved for future purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split labeled / unlabeled parts\n",
    "aylien_true = aylien[aylien[\"reliability\"] == 1]\n",
    "aylien_unlabeled = aylien[aylien[\"reliability\"] != 1]\n",
    "\n",
    "# Save the labeled / unlabeled parts separately\n",
    "with open(\"../data/processed/aylien_true\", \"wb\") as aylien_true_file:\n",
    "    pickle.dump(aylien_true, aylien_true_file)\n",
    "\n",
    "aylien_true.to_csv(\"../data/processed/aylien_true.csv\", index = False)\n",
    "\n",
    "with open(\"../data/processed/aylien_unlabeled\", \"wb\") as aylien_unlabeled_file:\n",
    "    pickle.dump(aylien_unlabeled, aylien_unlabeled_file)\n",
    "\n",
    "aylien_unlabeled.to_csv(\"../data/processed/aylien_unlabeled.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3043 entries, 55 to 49967\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   date         3043 non-null   object\n",
      " 1   content      3043 non-null   object\n",
      " 2   reliability  3043 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 95.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>reliability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>British postman delivers fancy dress joy to is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>India asks state-run power producers to ensure...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>Africa could lose 20 mln jobs due to pandemic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>New York state reports 594 coronavirus deaths ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>Elton John launches fund for HIV/AIDS work ami...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                            content reliability\n",
       "55   2020-04-05  British postman delivers fancy dress joy to is...           1\n",
       "60   2020-04-05  India asks state-run power producers to ensure...           1\n",
       "92   2020-04-05  Africa could lose 20 mln jobs due to pandemic ...           1\n",
       "111  2020-04-05  New York state reports 594 coronavirus deaths ...           1\n",
       "118  2020-04-05  Elton John launches fund for HIV/AIDS work ami...           1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the aylien_true dataset\n",
    "aylien_true.info()\n",
    "aylien_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46941 entries, 0 to 49999\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   date         46941 non-null  object\n",
      " 1   content      46941 non-null  object\n",
      " 2   reliability  0 non-null      object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>reliability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>Year 12 could be extended into next year in th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>Coronavirus: Trump upbeat as New York reports ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>Mets might be MLB’s biggest loser in the coron...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>Key Words: Bill Gates shares his optimistic ta...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>Is NIO Inc. (NIO) A Good Stock To Buy?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                            content reliability\n",
       "0  2020-04-05  Year 12 could be extended into next year in th...         NaN\n",
       "1  2020-04-05  Coronavirus: Trump upbeat as New York reports ...         NaN\n",
       "2  2020-04-05  Mets might be MLB’s biggest loser in the coron...         NaN\n",
       "3  2020-04-05  Key Words: Bill Gates shares his optimistic ta...         NaN\n",
       "4  2020-04-05             Is NIO Inc. (NIO) A Good Stock To Buy?         NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the aylien_unlabeled dataset\n",
    "aylien_unlabeled.info()\n",
    "aylien_unlabeled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the **FNIR** Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now perform similar operations on the **FNIR** dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "fnir_fake = pd.read_csv(\"../data/raw/fakeNews.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melon\\AppData\\Local\\Temp\\ipykernel_25360\\2408399608.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  fnir_fake = fnir_fake.drop([\"Link\", \"Region\", \"Country\", \"Explanation\", \"Origin\", \"Origin_URL\", \"Fact_checked_by\", \"Poynter_Label\"], 1)\n"
     ]
    }
   ],
   "source": [
    "# Drop entries that have null values\n",
    "fnir_fake = fnir_fake.dropna()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "fnir_fake = fnir_fake.drop([\"Link\", \"Region\", \"Country\", \"Explanation\", \"Origin\", \"Origin_URL\", \"Fact_checked_by\", \"Poynter_Label\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns for Consistency\n",
    "fnir_fake = fnir_fake.rename(columns = {\"Date Posted\": \"date\", \"Text\": \"content\", \"Binary Label\": \"reliability\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process DATE\n",
    "fnir_fake[\"date\"] = fnir_fake[\"date\"].apply(get_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Datasets\n",
    "with open(\"../data/processed/fnir_fake\", \"wb\") as fnir_fake_file:\n",
    "    pickle.dump(fnir_fake, fnir_fake_file)\n",
    "\n",
    "fnir_fake.to_csv(\"../data/processed/fnir_fake.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3610 entries, 0 to 3609\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   date         3610 non-null   object\n",
      " 1   content      3610 non-null   object\n",
      " 2   reliability  3610 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 84.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>reliability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>Tencent revealed the real number of deaths.\\t\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>Taking chlorine dioxide helps fight coronavir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>This video shows workmen uncovering a bat-inf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>The Asterix comic books and The Simpsons pred...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>Chinese President Xi Jinping visited a mosque...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                            content  reliability\n",
       "0  2020-02-07    Tencent revealed the real number of deaths.\\t\\t            0\n",
       "1  2020-02-07   Taking chlorine dioxide helps fight coronavir...            0\n",
       "2  2020-02-07   This video shows workmen uncovering a bat-inf...            0\n",
       "3  2020-02-07   The Asterix comic books and The Simpsons pred...            0\n",
       "4  2020-02-07   Chinese President Xi Jinping visited a mosque...            0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the FNIR dataset\n",
    "fnir_fake.info()\n",
    "fnir_fake.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging **Aylien** and **FNIR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Datasets\n",
    "final = pd.concat([aylien_true, fnir_fake], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataset\n",
    "with open(\"../data/processed/final\", \"wb\") as final_file:\n",
    "    pickle.dump(final, final_file)\n",
    "\n",
    "final.to_csv(\"../data/processed/final.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b57cc95ab6284b0134c7c3eb3216b5a5ac657b829297d979dc5e08ddada2f627"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
